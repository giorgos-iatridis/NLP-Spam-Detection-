ΠΕΡΙΓΡΑΦΗ
---------
Ο παρών φάκελος περιέχει τον πηγαίο κώδικα, τα δεδομένα και τα εκπαιδευμένα μοντέλα
που αναπτύχθηκαν στο πλαίσιο της εργασίας.

ΔΟΜΗ ΦΑΚΕΛΟΥ (DIRECTORY STRUCTURE)
----------------------------------
.
├── dataset/
│   ├── raw/                   # Αρχικά, ακατέργαστα δεδομένα (CEAS, Nazario, κτλ.)
│   └── preprocessed/          # Επεξεργασμένα δεδομένα (emails_train.csv, emails_test.csv)
│
├── Google/
│   └── GoogleNews-vectors...  # Προ-εκπαιδευμένο μοντέλο Word2Vec (αρχείο .bin.gz)
			      # Δεν περιέχεται για λόγους χωρητικότητας (βλ. Οδηγίες Εγκατάστασης)
│
├── saved_models/              # Φάκελος αποθήκευσης των μοντέλων (.joblib / .json)
│
├── 0_ETL.py                   # Κώδικας καθαρισμού και προεπεξεργασίας (Extract-Transform-Load)
├── 1_EDA.ipynb                # Jupyter Notebook για Εξερευνητική Ανάλυση Δεδομένων
├── 2_lgr.py                   # Logistic Regression - TF-IDF, αρχικός κώδικας για παραμετροποίηση
├── 3_best_LgR.py              # Εκπαίδευση & Αξιολόγηση βέλτιστου Logistic Regression
├── 4_xgboost.py               # XGBoost - Word2Vec
├── 5_best_xgb.py              # Εκπαίδευση & Αξιολόγηση βέλτιστου XGBoost
├── 6_metrics.ipynb            # Jupyter Notebook για τελική σύγκριση
├── config.py                  # Αρχείο ρυθμίσεων (paths, stopwords, κτλ.)
├── requirements.txt           # Λίστα απαιτούμενων βιβλιοθηκών Python
└── README.txt                 # Το παρόν αρχείο οδηγιών


ΕΓΚΑΤΑΣΤΑΣΗ & ΑΠΑΙΤΗΣΕΙΣ (INSTALLATION)
---------------------------------------
1. Συνιστάται η δημιουργία ενός εικονικού περιβάλλοντος (virtual environment).
2. Εγκατάσταση των βιβλιοθηκών:
   pip install -r requirements.txt

3. Λήψη του γλωσσικού μοντέλου της βιβλιοθήκης spaCy:
   python -m spacy download en_core_web_sm

4. Google Word2Vec:
   Λήψη του αρχείου GoogleNews-vectors-negative300.bin.gz δηλαδή του προ-εκπαιδευμένου μοντέλου της Google από τον σύνδεσμο:

   https://github.com/mmihaltz/word2vec-GoogleNews-vectors
   
   και τοποθέτησή του στον φάκελο "google". Η εφαρμογή διαβάζει απευθείας το συμπιεσμένο αρχείο, οπότε δεν απαιτείται αποσυμπίεση.


ΟΔΗΓΙΕΣ ΕΚΤΕΛΕΣΗΣ (EXECUTION ORDER)
-----------------------------------
Τα αρχεία πρέπει να εκτελεστούν με την ακόλουθη σειρά για την αναπαραγωγή των αποτελεσμάτων:

ΒΗΜΑ 1: Προεπεξεργασία
   Τρέξτε το `0_ETL.py`. (Χρόνος εκτέλεσης ~24 λεπτά, αναλόγως το λειτουργικό σύστημα)
   - Διαβάζει τα raw δεδομένα.
   - Εκτελεί καθαρισμό, NLP processing και split.
   - Αποθηκεύει τα `emails_train.csv` και `emails_test.csv` στο φάκελο `dataset/preprocessed/`.

ΒΗΜΑ 2: Εξερευνητική Ανάλυση (Προαιρετικό)
   Ανοίξτε και τρέξτε το `1_EDA.ipynb` για να δείτε τα γραφήματα και τα στατιστικά
   που περιγράφονται στην εργασία.

ΒΗΜΑ 3: Εκπαίδευση Μοντέλων
   
   A. LOGISTIC REGRESSION:
      - `2_lgr.py`: Εκτελεί GridSearch για εύρεση παραμέτρων (χρόνος εκτέλεσης ~1 λεπτό).
      - `3_best_LgR.py`: Εκπαιδεύει το βέλτιστο μοντέλο άμεσα και εμφανίζει τα αποτελέσματα.
        (Συνιστάται η εκτέλεση του `3_best_LgR.py` για γρήγορη επιβεβαίωση, χρόνος εκτέλεσης ~20 δευτερόλεπτα).

   B. XGBOOST:
      - `4_xgboost.py`: Εκτελεί GridSearch για το XGBoost (χρόνος εκτέλεσης ~15 λεπτά).
      - `5_best_xgb.py`: Εκπαιδεύει το βέλτιστο XGBoost με Word2Vec και εμφανίζει τα αποτελέσματα.
        (Συνιστάται η εκτέλεση του `5_best_xgb.py` για γρήγορη επιβεβαίωση, χρόνος εκτέλεσης περίπου 5 λεπτά).

ΒΗΜΑ 4: Σύγκριση & Μετρικές (απαιτείται η εκτέλεση των `3_best_LgR.py` και `5_best_xgb.py`)
   Ανοίξτε το `6_metrics.ipynb`.
   - Φορτώνει τα αποθηκευμένα μοντέλα από το φάκελο `saved_models/`.
   - Παράγει classification reports, confusion matrices, error analysis, wins/loses των μοντέλων

ΣΗΜΕΙΩΣΕΙΣ
----------
- Το αρχείο `config.py` περιέχει όλες τις διαδρομές αρχείων (paths).